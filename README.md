# Advances in 4D Generation: A Survey [![ArXiv](https://img.shields.io/badge/arXiv-2503.14501-red)](https://arxiv.org/abs/2503.14501)

**Qiaowei Miao**, **Kehan Li**, **Jinsheng Quan**, **Zhiyuan Min**, **Shaojie Ma**, **Yichao Xu**, **Yi Yang**, and **Yawei Luo**<sup>+</sup>.

<sup>+</sup> Corresponding Author.


------

> **We welcome authors of other 4D generation-related works to share their contributions and help expand this field together. Please feel free to contact [QiaoweiMiao@zju.edu.cn](mailto:QiaoweiMiao@zju.edu.cn), and we will regularly update your work in the repository and the main text. If you use WeChat, you are also welcome to reach out to: JoviMeow.**

This repository  is a collection of awesome things about papers, codes, datasets, etc.

If you would like to contribute to our repository or have any questions/advice.

# Papers

------

> We list the papers about 4D generation.


### MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow (2025.2)

**Authors**: Hanzhuo Huang, Yuan Liu, Ge Zheng, Jiepeng Wang, Zhiyang Dou, Sibei Yang

[ğŸ“„ Paper](https://arxiv.org/abs/2502.11697) | [ğŸŒ Project Page](https://soolab.github.io/MVTokenFlow/) | [ğŸ’» Code](https://github.com/SooLab/MVTokenFlow)

### AR4D: Autoregressive 4D Generation from Monocular Videos (2025.1)

**Authors**: Hanzhuo Huang, Yuan Liu, Ge Zheng, Jiepeng Wang, Zhiyang Dou, Sibei Yang

[ğŸ“„ Paper](https://arxiv.org/abs/2501.01722) | [ğŸŒ Project Page](https://hanxinzhu-lab.github.io/AR4D/) | [ğŸ’» Code](https://hanxinzhu-lab.github.io/AR4D/)


### PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting (2024.11)

**Authors**: Qiaowei Miao, JinSheng Quan, Kehan Li, Yawei Luo

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.19957)

### 4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models (2024.11)

**Authors**: Heng Yu, Chaoyang Wang, Peiye Zhuang, Willi Menapace, Aliaksandr Siarohin, Junli Cao, Laszlo A Jeni, Sergey
Tulyakov, Hsin-Ying Lee

[ğŸ“„ Paper](https://arxiv.org/pdf/2406.07472) | [ğŸŒ Project Page](https://snap-research.github.io/4Real/)

### DreamMesh4D: Video-to-4D Generation with Sparse-Controlled Gaussian-Mesh Hybrid Representation (2024.10)

**Authors**: Zhiqi Li, Yiming Chen, Peidong Liu

[ğŸ“„ Paper](https://arxiv.org/pdf/2410.06756) | [ğŸŒ Project Page](https://lizhiqi49.github.io/DreamMesh4D/) | [ğŸ’» Code](https://github.com/WU-CVGL/DreamMesh4D)

### AvatarGO: Zero-shot 4D Human-Object Interaction Generation and Animation (2024.10)

**Authors**: Yukang Cao, Liang Pan, Kai Han, Kwan-Yee K. Wong, Ziwei Liu

[ğŸ“„ Paper](https://arxiv.org/pdf/2410.07164) | [ğŸŒ Project Page](https://yukangcao.github.io/AvatarGO/) | [ğŸ’» Code](https://github.com/UPC-ViRVIG/AvatarGo) | [ğŸ¥ Short Presentation](https://youtu.be/DWU4p-a-uXo)

### ElastoGen: 4D Generative Elastodynamics (2024.10)

**Authors**: Yutao Feng, Yintong Shang, Xiang Feng, Lei Lan, Shandian Zhe, Tianjia Shao, Hongzhi Wu, Kun Zhou, Hao Su,
Chenfanfu Jiang, Yin Yang

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.15056) | [ğŸŒ Project Page](https://anunrulybunny.github.io/elastogen/) | [ğŸ¥ Short Presentation](https://anunrulybunny.github.io/elastogen/static/video/elastogen_video_compressed.mp4)

### 4Diffusion: Multi-view Video Diffusion Model for 4D Generation (2024.10)

**Authors**: Haiyu Zhang, Xinyuan Chen, Yaohui Wang, Xihui Liu, Yunhong Wang, Yu Qiao

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.20674) | [ğŸŒ Project Page](https://aejion.github.io/4diffusion/) | [ğŸ’» Code](https://github.com/aejion/4Diffusion) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=B-4XaDnlD68)

### DiffusionÂ²: Dynamic 3D Content Generation via Score Composition of Video and Multi-view Diffusion Models (2024.10)

**Authors**: Zeyu Yang, Zijie Pan, Chun Gu, Li Zhang

[ğŸ“„ Paper](https://arxiv.org/pdf/2404.02148)

### TC4D: Trajectory-Conditioned Text-to-4D Generation (2024.10)

**Authors**: Sherwin Bahmani, Xian Liu, Wang Yifan, Ivan Skorokhodov, Victor Rong, Ziwei Liu, Xihui Liu, Jeong Joon
Park, Sergey Tulyakov, Gordon Wetzstein, Andrea Tagliasacchi, David B. Lindell

[ğŸ“„ Paper](https://arxiv.org/pdf/2403.17920) | [ğŸŒ Project Page](https://sherwinbahmani.github.io/tc4d/) | [ğŸ’» Code](https://github.com/sherwinbahmani/tc4d)

### Sketch-2-4D: Sketch driven dynamic 3D scene generation (2024.10)

**Authors**: Guo-Wei Yang, Dong-Yu Chen, Tai-Jiang Mu

[ğŸ“„ Paper](http://iccvm.org/2024/papers/s1p3-292-gmod.pdf)

### Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis (2024.10)

**Authors**: Bohan Zeng, Ling Yang, Siyu Li, Jiaming Liu, Zixiang Zhang, Juanxi Tian, Kaixin Zhu, Yongzhen Guo, Fu-Yun
Wang, Minkai Xu, Stefano Ermon, Wentao Zhang

[ğŸ“„ Paper](https://arxiv.org/pdf/2410.07155) | [ğŸŒ Project Page](https://github.com/YangLing0818/Trans4D)

### Compositional 3D-aware Video Generation with LLM Director (2024.9)

**Authors**: Hanzhuo Huang, Yuan Liu, Ge Zheng, Jiepeng Wang, Zhiyang Dou, Sibei Yang

[ğŸ“„ Paper](https://arxiv.org/abs/2409.00558 ) 

### Phy124: Fast Physics-Driven 4D Content Generation from a Single Image (2024.9)

**Authors**: Jiajing Lin, Zhenzhong Wang, Yongjie Hou, Yuzhou Tang, Min Jiang

[ğŸ“„ Paper](https://arxiv.org/pdf/2409.07179) | [ğŸŒ Project Page](https://anonymous.4open.science/r/BBF2/)

### Human4DiT: 360-degree Human Video Generation with 4D Diffusion Transformer (2024.9)

**Authors**: Ruizhi Shao, Youxin Pang, Zerong Zheng, Jingxiang Sun, Yebin Liu

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.17405) | [ğŸŒ Project Page](https://human4dit.github.io/) | [ğŸ’» Code](https://github.com/DSaurus/Human4DiT) | [ğŸ“€ Dataset](https://github.com/DSaurus/Human4DiT)

### Disco4D: Disentangled 4D Human Generation and Animation from a Single Image (2024.9)

**Authors**: Hui En Pang, Shuai Liu, Zhongang Cai, Lei Yang, Tianwei Zhang, Ziwei Liu

[ğŸ“„ Paper](https://arxiv.org/pdf/2409.17280) | [ğŸŒ Project Page](https://disco-4d.github.io/) | [ğŸ’» Code](https://github.com/disco-4d/Disco4D)

### SC4D: Sparse-Controlled Video-to-4D Generation and Motion Transfer (2024.8)

**Authors**: Zijie Wu, Chaohui Yu, Yanqin Jiang, Chenjie Cao, Fan Wang, Xiang Bai

[ğŸ“„ Paper](https://arxiv.org/pdf/2404.03736) | [ğŸŒ Project Page](https://sc4d.github.io/) | [ğŸ’» Code](https://github.com/JarrentWu1031/SC4D) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=SkpTEuX4B5c)

### CT4D: Consistent Text-to-4D Generation with Animatable Meshes (2024.8)

**Authors**: Ce Chen, Shaoli Huang, Xuelin Chen, Guangyi Chen, Xiaoguang Han, Kun Zhang, Mingming Gong

[ğŸ“„ Paper](https://arxiv.org/pdf/2408.08342)

### SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency (2024.7)

**Authors**: Yiming Xie, Chun-Han Yao1, Vikram Voleti1, Huaizu Jiang, Varun Jampani

[ğŸ“„ Paper](https://arxiv.org/pdf/2407.17470) | [ğŸŒ Project Page](https://sv4d.github.io/) | [ğŸ’» Code](https://github.com/Stability-AI/generative-models) | [ğŸ¥ Short Presentation](https://stability.ai/news/stable-video-4d)

### Sync4D: Video Guided Controllable Dynamics for Physics-Based 4D Generation (2024.7)

**Authors**: Zhoujie Fu, Jiacheng Wei, Wenhao Shen, Chaoyue Song, Xiaofeng Yang, Fayao Liu, Xulei Yang, Guosheng Lin

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.16849) | [ğŸŒ Project Page](https://sync4dphys.github.io/?ref=aiartweekly)

### 4Dynamic: Text-to-4D Generation with Hybrid Priors (2024.7)

**Authors**: Yu-Jie Yuan, Leif Kobbelt, Jiwen Liu, Yuan Zhang, Pengfei Wan, Yu-Kun Lai, Lin Gao

[ğŸ“„ Paper](https://arxiv.org/pdf/2407.12684)

### L4GM: Large 4D Gaussian Reconstruction Model (2024.6)

**Authors**: Jiawei Ren, Kevin Xie, Ashkan Mirzaei, Hanxue Liang, Xiaohui Zeng, Karsten Kreis, Ziwei Liu, Antonio
Torralba, Sanja Fidler, Seung Wook Kim, Huan Ling

[ğŸ“„ Paper](https://arxiv.org/pdf/2406.10324) | [ğŸŒ Project Page](https://research.nvidia.com/labs/toronto-ai/l4gm/) | [ğŸ’» Code](https://github.com/nv-tlabs/L4GM-official)

### STAR: Skeleton-aware Text-based 4D Avatar Generation with In-Network Motion Retargeting (2024.6)

**Authors**: Zenghao Chai, Chen Tang, Yongkang Wong, Mohan Kankanhalli

[ğŸ“„ Paper](https://arxiv.org/pdf/2406.04629) | [ğŸŒ Project Page](https://star-avatar.github.io/) | [ğŸ’» Code](https://github.com/czh-98/STAR)

### EG4D: Explicit Generation of 4D Object without Score Distillation (2024.5)

**Authors**: Qi Sun, Zhiyang Guo, Ziyu Wan, Jing Nathan Yan, Shengming Yin, Wengang Zhou, Jing Liao, Houqiang Li

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.18132v1) | [ğŸ’» Code](https://github.com/jasongzy/EG4D)

### Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models (2024.5)

**Authors**: Hanwen Liang, Yuyang Yin, Dejia Xu, Hanxue Liang, Zhangyang Wang, Konstantinos N. Plataniotis, Yao Zhao,
Yunchao Wei

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.16645) | [ğŸŒ Project Page](https://vita-group.github.io/Diffusion4D/) | [ğŸ’» Code](https://github.com/VITA-Group/Diffusion4D) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=XJT-cMt_xVo) | [ğŸ“€ Dataset](https://huggingface.co/datasets/hw-liang/Diffusion4D)

### A Unified Approach for Text- and Image-guided 4D Scene Generation (2024.5)

**Authors**: Yufeng Zheng, Xueting Li, Koki Nagano, Sifei Liu, Karsten Kreis, Otmar Hilliges, Shalini De Mello

[ğŸ“„ Paper](https://arxiv.org/pdf/2311.16854) | [ğŸŒ Project Page](https://research.nvidia.com/labs/nxp/dream-in-4d/) | [ğŸ’» Code](https://github.com/NVlabs/dream-in-4d)

### 4K4DGen: Panoramic 4D Generation at 4K Resolution (2024.3)

**Authors**: Renjie Li, Panwang Pan, Bangbang Yang, Dejia Xu, Shijie Zhou, Xuanyang Zhang, Zeming Li, Achuta Kadambi,
Zhangyang Wang, Zhengzhong Tu, Zhiwen Fan

[ğŸ“„ Paper](https://arxiv.org/pdf/2406.13527) | [ğŸŒ Project Page](https://4k4dgen.github.io/) | [ğŸ¥ Short Presentation](https://4k4dgen.github.io/index.html)

### Beyond Skeletons: Integrative Latent Mapping for Coherent 4D Sequence Generation (2024.3)

**Authors**: Qitong Yang, Mingtao Feng, Zijie Wu, Shijie Sun, Weisheng Dong, Yaonan Wang, Ajmal Mian

[ğŸ“„ Paper](https://arxiv.org/pdf/2403.13238)

### Comp4D: LLM-Guided Compositional 4D Scene Generation (2024.3)

**Authors**: Dejia Xu, Hanwen Liang, Neel P. Bhatt, Hezhen Hu, Hanxue Liang, Konstantinos N. Plataniotis, Zhangyang Wang

[ğŸ“„ Paper](https://arxiv.org/pdf/2403.16993) | [ğŸŒ Project Page](https://vita-group.github.io/Comp4D/) | [ğŸ’» Code](https://github.com/VITA-Group/Comp4D) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=gXVoPTGb734)

### Animate124: Animating One Image to 4D Dynamic Scene (2024.2)

**Authors**: Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee

[ğŸ“„ Paper](https://arxiv.org/pdf/2311.14603) | [ğŸŒ Project Page](https://animate124.github.io/) | [ğŸ’» Code](https://github.com/HeliosZhao/Animate124) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=L_1HCBhz9MM)

### 4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency (2023.12)

**Authors**: Yuyang Yin, Dejia Xu, Zhangyang Wang, Yao Zhao, Yunchao Wei

[ğŸ“„ Paper](https://arxiv.org/pdf/2312.17225.pdf) | [ğŸŒ Project Page](https://vita-group.github.io/4DGen/) | [ğŸ’» Code](https://github.com/VITA-Group/4DGen) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=-bXyBKdpQ1o)

### DreamGaussian4D: Generative 4D Gaussian Splatting (2023.12)

**Authors**: Jiawei Ren, Liang Pan, Jiaxiang Tang, Chi Zhang, Ang Cao, Gang Zeng, Ziwei Liu

[ğŸ“„ Paper](https://arxiv.org/pdf/2312.17142.pdf) | [ğŸŒ Project Page](https://jiawei-ren.github.io/projects/dreamgaussian4d/) | [ğŸ’» Code](https://github.com/jiawei-ren/dreamgaussian4d)

### Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models (2023.12)

**Authors**: Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, Karsten Kreis

[ğŸ“„ Paper](https://arxiv.org/abs/2312.13763) | [ğŸŒ Project Page](https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/)

### AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation and Reconstruction with Canonical Score Distillation (2023.12)

**Authors**: Xinzhou Wang, Yikai Wang, Junliang Ye, Zhengyi Wang, Fuchun Sun, Pengkun Liu, Ling Wang, Kai Sun, Xintong
Wang, Bin He

[ğŸ“„ Paper](https://arxiv.org/abs/2312.03795) |  [ğŸŒ Project Page](https://animatabledreamer.github.io/)

### Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models (2023.12)

**Authors**: Shengqu Cai, Duygu Ceylan, Matheus Gadelha, Chun-Hao Paul Huang, Tuanfeng Yang Wang, Gordon Wetzstein

[ğŸ“„ Paper](https://arxiv.org/pdf/2312.01409) | [ğŸŒ Project Page](https://primecai.github.io/generative_rendering/)

### 4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling (2023.11)

**Authors**: Sherwin Bahmani, Ivan Skorokhodov, Victor Rong, Gordon Wetzstein, Leonidas Guibas, Peter Wonka, Sergey
Tulyakov, Jeong Joon Park, Andrea Tagliasacchi, David B. Lindell

[ğŸ“„ Paper](https://arxiv.org/abs/2311.17984) | [ğŸŒ Project Page](https://sherwinbahmani.github.io/4dfy/) | [ğŸ’» Code](https://github.com/sherwinbahmani/4dfy)

### A Unified Approach for Text- and Image-guided 4D Scene Generation (2023.11)

**Authors**: Yufeng Zheng, Xueting Li, Koki Nagano, Sifei Liu, Karsten Kreis, Otmar Hilliges, Shalini De Mello

[ğŸ“„ Paper](https://arxiv.org/abs/2311.16854)

### Consistent4D: Consistent 360Â° Dynamic Object Generation from Monocular Video (2023.11)

**Authors**:Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, Yao Yao

[ğŸ“„ Paper](https://arxiv.org/abs/2311.02848) | [ğŸŒ Project Page ](https://consistent4d.github.io/) | [ğŸ’» Code](https://github.com/yanqinJiang/Consistent4D)

### Animate124: Animating One Image to 4D Dynamic Scene (2023.11)

**Authors**: Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee

[ğŸ“„ Paper](https://arxiv.org/abs/2311.14603) | [ğŸŒ Project Page](https://animate124.github.io/) | [ğŸ’» Code](https://github.com/HeliosZhao/Animate124)| [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=L_1HCBhz9MM&ab_channel=YuyangZhao)

### HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion (2023.3)

**Authors**: Ziya ErkoÃ§, Fangchang Ma, Qi Shan, Matthias NieÃŸner, Angela Dai

[ğŸ“„ Paper](https://arxiv.org/pdf/2303.17015) | [ğŸŒ Project Page](https://www.ziyaerkoc.com/hyperdiffusion) | [ğŸ’» Code](https://github.com/Rgtemze/HyperDiffusion) | [ğŸ¥ Short Presentation](https://www.youtube.com/watch?v=wjFpsKdo-II) | [ğŸ“€ Dataset](https://drive.google.com/drive/folders/1CuNVa92jcKlGBiHEuCQK2-juAB6Q6QPx?usp=sharing)

### Text-To-4D Dynamic Scene Generation (2023.1)

**Authors**: Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal,
Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman

[ğŸ“„ Paper](https://arxiv.org/abs/2301.11280) | [ğŸŒ Project Page](https://make-a-video3d.github.io/)



