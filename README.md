# Awesome-4D

------

This repository  is a collection of awesome things about papers, codes, datasets, etc.

If you would like to contribute to our repository or have any questions/advice.

# Contents

------

[TOC]

# News

------

The recent news about 4Dï¼

```
Mesh GPT is publishedï¼ seeï¼š
```

# Papers

------

> We list the papers including survey,  4D, GS models and awesome editing methods.

# Awesome-4D-Generation

An organized list of academic papers focused on the topic of 4D Generation. If you have any additions or suggestions,
feel free to contribute.

### PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting (2024.11)

**Authors**: Qiaowei Miao, JinSheng Quan, Kehan Li, Yawei Luo

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.19957)

### 4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models (2024.11)

**Authors**: Heng Yu, Chaoyang Wang, Peiye Zhuang, Willi Menapace, Aliaksandr Siarohin, Junli Cao, Laszlo A Jeni, Sergey
Tulyakov, Hsin-Ying Lee

[ðŸ“„ Paper](https://arxiv.org/pdf/2406.07472) | [ðŸŒ Project Page](https://snap-research.github.io/4Real/)

### DreamMesh4D: Video-to-4D Generation with Sparse-Controlled Gaussian-Mesh Hybrid Representation (2024.10)

**Authors**: Zhiqi Li, Yiming Chen, Peidong Liu

[ðŸ“„ Paper](https://arxiv.org/pdf/2410.06756) | [ðŸŒ Project Page](https://lizhiqi49.github.io/DreamMesh4D/) | [ðŸ’» Code](https://github.com/WU-CVGL/DreamMesh4D)

### AvatarGO: Zero-shot 4D Human-Object Interaction Generation and Animation (2024.10)

**Authors**: Yukang Cao, Liang Pan, Kai Han, Kwan-Yee K. Wong, Ziwei Liu

[ðŸ“„ Paper](https://arxiv.org/pdf/2410.07164) | [ðŸŒ Project Page](https://yukangcao.github.io/AvatarGO/) | [ðŸ’» Code](https://github.com/UPC-ViRVIG/AvatarGo) | [ðŸŽ¥ Short Presentation](https://youtu.be/DWU4p-a-uXo)

### ElastoGen: 4D Generative Elastodynamics (2024.10)

**Authors**: Yutao Feng, Yintong Shang, Xiang Feng, Lei Lan, Shandian Zhe, Tianjia Shao, Hongzhi Wu, Kun Zhou, Hao Su,
Chenfanfu Jiang, Yin Yang

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.15056) | [ðŸŒ Project Page](https://anunrulybunny.github.io/elastogen/) | [ðŸŽ¥ Short Presentation](https://anunrulybunny.github.io/elastogen/static/video/elastogen_video_compressed.mp4)

### 4Diffusion: Multi-view Video Diffusion Model for 4D Generation (2024.10)

**Authors**: Haiyu Zhang, Xinyuan Chen, Yaohui Wang, Xihui Liu, Yunhong Wang, Yu Qiao

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.20674) | [ðŸŒ Project Page](https://aejion.github.io/4diffusion/) | [ðŸ’» Code](https://github.com/aejion/4Diffusion) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=B-4XaDnlD68)

### DiffusionÂ²: Dynamic 3D Content Generation via Score Composition of Video and Multi-view Diffusion Models (2024.10)

**Authors**: Zeyu Yang, Zijie Pan, Chun Gu, Li Zhang

[ðŸ“„ Paper](https://arxiv.org/pdf/2404.02148)

### TC4D: Trajectory-Conditioned Text-to-4D Generation (2024.10)

**Authors**: Sherwin Bahmani, Xian Liu, Wang Yifan, Ivan Skorokhodov, Victor Rong, Ziwei Liu, Xihui Liu, Jeong Joon
Park, Sergey Tulyakov, Gordon Wetzstein, Andrea Tagliasacchi, David B. Lindell

[ðŸ“„ Paper](https://arxiv.org/pdf/2403.17920) | [ðŸŒ Project Page](https://sherwinbahmani.github.io/tc4d/) | [ðŸ’» Code](https://github.com/sherwinbahmani/tc4d)

### Sketch-2-4D: Sketch driven dynamic 3D scene generation (2024.10)

**Authors**: Guo-Wei Yang, Dong-Yu Chen, Tai-Jiang Mu

[ðŸ“„ Paper](http://iccvm.org/2024/papers/s1p3-292-gmod.pdf)

### Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis (2024.10)

**Authors**: Bohan Zeng, Ling Yang, Siyu Li, Jiaming Liu, Zixiang Zhang, Juanxi Tian, Kaixin Zhu, Yongzhen Guo, Fu-Yun
Wang, Minkai Xu, Stefano Ermon, Wentao Zhang

[ðŸ“„ Paper](https://arxiv.org/pdf/2410.07155) | [ðŸŒ Project Page](https://github.com/YangLing0818/Trans4D)

### Phy124: Fast Physics-Driven 4D Content Generation from a Single Image (2024.9)

**Authors**: Jiajing Lin, Zhenzhong Wang, Yongjie Hou, Yuzhou Tang, Min Jiang

[ðŸ“„ Paper](https://arxiv.org/pdf/2409.07179) | [ðŸŒ Project Page](https://anonymous.4open.science/r/BBF2/)

### Human4DiT: 360-degree Human Video Generation with 4D Diffusion Transformer (2024.9)

**Authors**: Ruizhi Shao, Youxin Pang, Zerong Zheng, Jingxiang Sun, Yebin Liu

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.17405) | [ðŸŒ Project Page](https://human4dit.github.io/) | [ðŸ’» Code](https://github.com/DSaurus/Human4DiT) | [ðŸ“€ Dataset](https://github.com/DSaurus/Human4DiT)

### Disco4D: Disentangled 4D Human Generation and Animation from a Single Image (2024.9)

**Authors**: Hui En Pang, Shuai Liu, Zhongang Cai, Lei Yang, Tianwei Zhang, Ziwei Liu

[ðŸ“„ Paper](https://arxiv.org/pdf/2409.17280) | [ðŸŒ Project Page](https://disco-4d.github.io/) | [ðŸ’» Code](https://github.com/disco-4d/Disco4D)

### SC4D: Sparse-Controlled Video-to-4D Generation and Motion Transfer (2024.8)

**Authors**: Zijie Wu, Chaohui Yu, Yanqin Jiang, Chenjie Cao, Fan Wang, Xiang Bai

[ðŸ“„ Paper](https://arxiv.org/pdf/2404.03736) | [ðŸŒ Project Page](https://sc4d.github.io/) | [ðŸ’» Code](https://github.com/JarrentWu1031/SC4D) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=SkpTEuX4B5c)

### CT4D: Consistent Text-to-4D Generation with Animatable Meshes (2024.8)

**Authors**: Ce Chen, Shaoli Huang, Xuelin Chen, Guangyi Chen, Xiaoguang Han, Kun Zhang, Mingming Gong

[ðŸ“„ Paper](https://arxiv.org/pdf/2408.08342)

### SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency (2024.7)

**Authors**: Yiming Xie, Chun-Han Yao1, Vikram Voleti1, Huaizu Jiang, Varun Jampani

[ðŸ“„ Paper](https://arxiv.org/pdf/2407.17470) | [ðŸŒ Project Page](https://sv4d.github.io/) | [ðŸ’» Code](https://github.com/Stability-AI/generative-models) | [ðŸŽ¥ Short Presentation](https://stability.ai/news/stable-video-4d)

### Sync4D: Video Guided Controllable Dynamics for Physics-Based 4D Generation (2024.7)

**Authors**: Zhoujie Fu, Jiacheng Wei, Wenhao Shen, Chaoyue Song, Xiaofeng Yang, Fayao Liu, Xulei Yang, Guosheng Lin

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.16849) | [ðŸŒ Project Page](https://sync4dphys.github.io/?ref=aiartweekly)

### 4Dynamic: Text-to-4D Generation with Hybrid Priors (2024.7)

**Authors**: Yu-Jie Yuan, Leif Kobbelt, Jiwen Liu, Yuan Zhang, Pengfei Wan, Yu-Kun Lai, Lin Gao

[ðŸ“„ Paper](https://arxiv.org/pdf/2407.12684)

### L4GM: Large 4D Gaussian Reconstruction Model (2024.6)

**Authors**: Jiawei Ren, Kevin Xie, Ashkan Mirzaei, Hanxue Liang, Xiaohui Zeng, Karsten Kreis, Ziwei Liu, Antonio
Torralba, Sanja Fidler, Seung Wook Kim, Huan Ling

[ðŸ“„ Paper](https://arxiv.org/pdf/2406.10324) | [ðŸŒ Project Page](https://research.nvidia.com/labs/toronto-ai/l4gm/) | [ðŸ’» Code](https://github.com/nv-tlabs/L4GM-official)

### STAR: Skeleton-aware Text-based 4D Avatar Generation with In-Network Motion Retargeting (2024.6)

### DreamGaussian4D: Generative 4D Gaussian Splatting (2024.6)

**Authors**: Jiawei Ren, Liang Pan, Jiaxiang Tang, Chi Zhang, Ang Cao, Gang Zeng, Ziwei Liu

[ðŸ“„ Paper](https://arxiv.org/pdf/2312.17142) | [ðŸŒ Project Page](https://jiawei-ren.github.io/projects/dreamgaussian4d/) | [ðŸ’» Code](https://github.com/jiawei-ren/dreamgaussian4d) | [ðŸŽ¥ Short Presentation](https://huggingface.co/spaces/jiawei011/dreamgaussian4d)

**Authors**: Zenghao Chai, Chen Tang, Yongkang Wong, Mohan Kankanhalli

[ðŸ“„ Paper](https://arxiv.org/pdf/2406.04629) | [ðŸŒ Project Page](https://star-avatar.github.io/) | [ðŸ’» Code](https://github.com/czh-98/STAR)

### EG4D: Explicit Generation of 4D Object without Score Distillation (2024.5)

**Authors**: Qi Sun, Zhiyang Guo, Ziyu Wan, Jing Nathan Yan, Shengming Yin, Wengang Zhou, Jing Liao, Houqiang Li

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.18132v1) | [ðŸ’» Code](https://github.com/jasongzy/EG4D)

### Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models (2024.5)

**Authors**: Hanwen Liang, Yuyang Yin, Dejia Xu, Hanxue Liang, Zhangyang Wang, Konstantinos N. Plataniotis, Yao Zhao,
Yunchao Wei

[ðŸ“„ Paper](https://arxiv.org/pdf/2405.16645) | [ðŸŒ Project Page](https://vita-group.github.io/Diffusion4D/) | [ðŸ’» Code](https://github.com/VITA-Group/Diffusion4D) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=XJT-cMt_xVo) | [ðŸ“€ Dataset](https://huggingface.co/datasets/hw-liang/Diffusion4D)

### A Unified Approach for Text- and Image-guided 4D Scene Generation (2024.5)

**Authors**: Yufeng Zheng, Xueting Li, Koki Nagano, Sifei Liu, Karsten Kreis, Otmar Hilliges, Shalini De Mello

[ðŸ“„ Paper](https://arxiv.org/pdf/2311.16854) | [ðŸŒ Project Page](https://research.nvidia.com/labs/nxp/dream-in-4d/) | [ðŸ’» Code](https://github.com/NVlabs/dream-in-4d)

### 4K4DGen: Panoramic 4D Generation at 4K Resolution (2024.3)

**Authors**: Renjie Li, Panwang Pan, Bangbang Yang, Dejia Xu, Shijie Zhou, Xuanyang Zhang, Zeming Li, Achuta Kadambi,
Zhangyang Wang, Zhengzhong Tu, Zhiwen Fan

[ðŸ“„ Paper](https://arxiv.org/pdf/2406.13527) | [ðŸŒ Project Page](https://4k4dgen.github.io/) | [ðŸŽ¥ Short Presentation](https://4k4dgen.github.io/index.html)

### Beyond Skeletons: Integrative Latent Mapping for Coherent 4D Sequence Generation (2024.3)

**Authors**: Qitong Yang, Mingtao Feng, Zijie Wu, Shijie Sun, Weisheng Dong, Yaonan Wang, Ajmal Mian

[ðŸ“„ Paper](https://arxiv.org/pdf/2403.13238)

### Comp4D: LLM-Guided Compositional 4D Scene Generation (2024.3)

**Authors**: Dejia Xu, Hanwen Liang, Neel P. Bhatt, Hezhen Hu, Hanxue Liang, Konstantinos N. Plataniotis, Zhangyang Wang

[ðŸ“„ Paper](https://arxiv.org/pdf/2403.16993) | [ðŸŒ Project Page](https://vita-group.github.io/Comp4D/) | [ðŸ’» Code](https://github.com/VITA-Group/Comp4D) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=gXVoPTGb734)

### Animate124: Animating One Image to 4D Dynamic Scene (2024.2)

**Authors**: Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee

[ðŸ“„ Paper](https://arxiv.org/pdf/2311.14603) | [ðŸŒ Project Page](https://animate124.github.io/) | [ðŸ’» Code](https://github.com/HeliosZhao/Animate124) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=L_1HCBhz9MM)

### 4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency (2023.12)

**Authors**: Yuyang Yin, Dejia Xu, Zhangyang Wang, Yao Zhao, Yunchao Wei

[ðŸ“„ Paper](https://arxiv.org/pdf/2312.17225.pdf) | [ðŸŒ Project Page](https://vita-group.github.io/4DGen/) | [ðŸ’» Code](https://github.com/VITA-Group/4DGen) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=-bXyBKdpQ1o)

### DreamGaussian4D: Generative 4D Gaussian Splatting (2023.12)

**Authors**: Jiawei Ren, Liang Pan, Jiaxiang Tang, Chi Zhang, Ang Cao, Gang Zeng, Ziwei Liu

[ðŸ“„ Paper ](https://arxiv.org/pdf/2312.17142.pdf) | [ðŸŒ Project Page](https://jiawei-ren.github.io/projects/dreamgaussian4d/) | [ðŸ’» Code](https://github.com/jiawei-ren/dreamgaussian4d)

### Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models (2023.12)

**Authors**: Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, Sanja Fidler, Karsten Kreis

[ðŸ“„ Paper](https://arxiv.org/abs/2312.13763) | [ðŸŒ Project Page](https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/)

### AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation and Reconstruction with Canonical Score Distillation (2023.12)

**Authors**: Xinzhou Wang, Yikai Wang, Junliang Ye, Zhengyi Wang, Fuchun Sun, Pengkun Liu, Ling Wang, Kai Sun, Xintong
Wang, Bin He

[ðŸ“„ Paper](https://arxiv.org/abs/2312.03795) |  [ðŸŒ Project Page](https://animatabledreamer.github.io/)

### Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models (2023.12)

**Authors**: Shengqu Cai, Duygu Ceylan, Matheus Gadelha, Chun-Hao Paul Huang, Tuanfeng Yang Wang, Gordon Wetzstein

[ðŸ“„ Paper](https://arxiv.org/pdf/2312.01409) | [ðŸŒ Project Page](https://primecai.github.io/generative_rendering/)

### 4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling (2023.11)

**Authors**: Sherwin Bahmani, Ivan Skorokhodov, Victor Rong, Gordon Wetzstein, Leonidas Guibas, Peter Wonka, Sergey
Tulyakov, Jeong Joon Park, Andrea Tagliasacchi, David B. Lindell

[ðŸ“„ Paper](https://arxiv.org/abs/2311.17984) | [ðŸŒ Project Page](https://sherwinbahmani.github.io/4dfy/) | [ðŸ’» Code](https://github.com/sherwinbahmani/4dfy)

### A Unified Approach for Text- and Image-guided 4D Scene Generation (2023.11)

**Authors**: Yufeng Zheng, Xueting Li, Koki Nagano, Sifei Liu, Karsten Kreis, Otmar Hilliges, Shalini De Mello

[ðŸ“„ Paper](https://arxiv.org/abs/2311.16854)

### Consistent4D: Consistent 360Â° Dynamic Object Generation from Monocular Video (2023.11)

**Authors**:Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, Yao Yao

[ðŸ“„ Paper](https://arxiv.org/abs/2311.02848) | [ðŸŒ Project Page ](https://consistent4d.github.io/) | [ðŸ’» Code](https://github.com/yanqinJiang/Consistent4D)

### Animate124: Animating One Image to 4D Dynamic Scene (2023.11)

**Authors**: Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee

[ðŸ“„ Paper](https://arxiv.org/abs/2311.14603) | [ðŸŒ Project Page](https://animate124.github.io/) | [ðŸ’» Code](https://github.com/HeliosZhao/Animate124)| [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=L_1HCBhz9MM&ab_channel=YuyangZhao)

### HyperDiffusion: Generating Implicit Neural Fields with Weight-Space Diffusion (2023.3)

**Authors**: Ziya ErkoÃ§, Fangchang Ma, Qi Shan, Matthias NieÃŸner, Angela Dai

[ðŸ“„ Paper](https://arxiv.org/pdf/2303.17015) | [ðŸŒ Project Page](https://www.ziyaerkoc.com/hyperdiffusion) | [ðŸ’» Code](https://github.com/Rgtemze/HyperDiffusion) | [ðŸŽ¥ Short Presentation](https://www.youtube.com/watch?v=wjFpsKdo-II) | [ðŸ“€ Dataset](https://drive.google.com/drive/folders/1CuNVa92jcKlGBiHEuCQK2-juAB6Q6QPx?usp=sharing)

### Text-To-4D Dynamic Scene Generation (2023.1)

**Authors**: Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal,
Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman

[ðŸ“„ Paper](https://arxiv.org/abs/2301.11280) | [ðŸŒ Project Page](https://make-a-video3d.github.io/)

### Text-To-4D Dynamic Scene Generation (2023.1)

**Authors**: Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal,
Andrea Vedaldi, Devi Parikh, Justin Johnson, Yaniv Taigman

[ðŸ“„ Paper](https://arxiv.org/pdf/2301.11280) | [ðŸŒ Project Page](https://make-a-video3d.github.io/) 



## Base models

------



- Nerf: Neural radiance field in 3d vision, a comprehensive review [[paper](https://arxiv.org/abs/2210.00379), [code](https://paperswithcode.com/method/nerf)]
- HyperReel: High-fidelity 6-DoF video with ray-conditioned sampling [[paper](http://openaccess.thecvf.com/content/CVPR2023/papers/Attal_HyperReel_High-Fidelity_6-DoF_Video_With_Ray-Conditioned_Sampling_CVPR_2023_paper.pdf), [code](https://github.com/facebookresearch/hyperreel)]

## Generation

------





## Editing

------

> We list 

### Mesh

### Point cloud

### Text-based



# Datasets

------

- DONeRF: Towards Real-Time Rendering of Compact Neural Radiance Fields using Depth Oracle Networks [[paper](),[code](https://github.com/facebookresearch/DONERF)]
- NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis 
- Dataset and Pipeline for Multi-view Light-Field Video
- Neural 3D Video Synthesis from Multi-view Video
- Immersive light field video with a layered mesh representation
- DeepView: View Synthesis With Learned Gradient Descent



# Idea

------

![Basic Idea](idea.png)

# Publications

------

| Dataset          | Details                                                      | Papers |
| ---------------- | ------------------------------------------------------------ | ------ |
| DoNeRF           | 800Ã—800ï¼›                                                    |        |
| LLFF             |                                                              |        |
| Technicolor      | 2048Ã—1088l; five sences (Birthday, Fabien, Painter, Theater, Trains); |        |
| Neural 3D Video  | 2704Ã—2028;                                                   |        |
| Google Immersive | 2048*1920; seven sences (Welder, Flames, Truck, Exhibit, Face Paint 1, Face Paint 2, Cave) |        |
| DeepView         |                                                              |        |
|                  |                                                              |        |



